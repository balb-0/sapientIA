{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2PwVOXaiH1E"
      },
      "source": [
        "# **Configuração de ambiente**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3bS6cfCiFBe"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pmdarima as pm\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvalEjKBiMBd"
      },
      "source": [
        "# Carregamento do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Utilização do gdown\n",
        "\n",
        "A biblioteca `gdown` esta sendo utilizada para baixar arquivos diretamente do Google Drive. Especificamente, o arquivo com o ID `1BeB7U-Y-wN5L5XnSw-QIpph4MXd93g0V` é baixado e salvo localmente como `df_final_novas_features2.csv`. Este arquivo contém o dataset que será utilizado nas etapas subsequentes de análise e modelagem.\n",
        "\n",
        "O código para realizar o download é o seguinte:\n",
        "\n",
        "```python\n",
        "import gdown\n",
        "\n",
        "# URL do arquivo no Google Drive\n",
        "url = 'https://drive.google.com/uc?id=1BeB7U-Y-wN5L5XnSw-QIpph4MXd93g0V'\n",
        "\n",
        "# Baixar o arquivo\n",
        "gdown.download(url, 'df_final_novas_features2.csv', quiet=False)\n",
        "```\n",
        "\n",
        "Após o download, o dataset é carregado em um DataFrame do pandas para posterior tratamento e análise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# baixando o gdown para baixar o arquivo de dados\n",
        "\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXuidAlViAMy"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "# Colocar o ID do arquivo aqui (substitua 'FILE_ID' pelo ID correto)\n",
        "file_id = '1BeB7U-Y-wN5L5XnSw-QIpph4MXd93g0V'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "# - https://drive.google.com/file/d/1BeB7U-Y-wN5L5XnSw-QIpph4MXd93g0V/view?usp=sharing\n",
        "\n",
        "# Baixar o arquivo\n",
        "gdown.download(url, 'df_final_novas_features2.csv', quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAROkv36iDJH"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('df_final_novas_features2.csv')\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W59P2b9Tiqqf"
      },
      "source": [
        "# Pequeno tratamento de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRoWWq7XiMds"
      },
      "outputs": [],
      "source": [
        "# Convert 'year' and 'month' to datetime\n",
        "df['date'] = pd.to_datetime(df[['year', 'month']].assign(DAY=1))\n",
        "\n",
        "# Aggregate 'Vl Liquido Final' by 'date' and 'Origem'\n",
        "agg_df = df.groupby(['date', 'Origem'])['Vl Liquido Final'].sum().reset_index()\n",
        "\n",
        "# Display the aggregated data\n",
        "agg_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptO8mO6-ivey"
      },
      "source": [
        "# Visualização do dataset por origem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmdUVzSsikJf"
      },
      "outputs": [],
      "source": [
        "# Plot the time series of 'Vl Liquido Final' for each 'Origem'\n",
        "origem_list = agg_df['Origem'].unique()\n",
        "\n",
        "for origem in origem_list:\n",
        "    origem_df = agg_df[agg_df['Origem'] == origem]\n",
        "    plt.figure(figsize=(12,6))\n",
        "    plt.plot(origem_df['date'], origem_df['Vl Liquido Final'], marker='o')\n",
        "    plt.title(f'Vl Liquido Final Over Time for Origem {origem}')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Vl Liquido Final')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDWCj3oUjOdV"
      },
      "source": [
        "## Inicializa a lista de origens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYy5NTOziOCM"
      },
      "outputs": [],
      "source": [
        "# Get the list of unique 'Origem' values\n",
        "origem_list = agg_df['Origem'].unique()\n",
        "\n",
        "# Dictionary to store models for each 'Origem'\n",
        "models = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TJmQJ-yi68K"
      },
      "source": [
        "# Função para avaliar o modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mVATosGkX5P"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate the model\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    # Handle division by zero in MAPE\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    non_zero_indices = y_true != 0\n",
        "    mape = np.mean(np.abs((y_true[non_zero_indices] - y_pred[non_zero_indices]) / y_true[non_zero_indices])) * 100\n",
        "    return mae, rmse, mape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aCEjbEVhtwe"
      },
      "source": [
        "# Treinamento por origem\n",
        "Divide dados em treino e teste, plota os gráficos comparando valores reais com previsto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OC2LM5QUkaL0",
        "outputId": "93bfd83a-0c9c-40cf-e53d-e5e62bbfc270"
      },
      "outputs": [],
      "source": [
        "# Loop through each 'Origem' and build a model\n",
        "for origem in origem_list:\n",
        "    print(f\"Processing Origem: {origem}\")\n",
        "\n",
        "    # Filter data for the current 'Origem'\n",
        "    origem_df = agg_df[agg_df['Origem'] == origem].copy()\n",
        "\n",
        "    # Set 'date' as the index\n",
        "    origem_df.set_index('date', inplace=True)\n",
        "\n",
        "    # Ensure the time series is sorted\n",
        "    origem_df.sort_index(inplace=True)\n",
        "\n",
        "    # Check if there are enough data points\n",
        "    if len(origem_df) < 24:\n",
        "        print(f\"Not enough data for Origem {origem}. Skipping...\")\n",
        "        continue\n",
        "\n",
        "    # Split into training and testing sets (80% train, 20% test)\n",
        "    train_size = int(len(origem_df) * 0.8)\n",
        "    train_data = origem_df.iloc[:train_size]\n",
        "    test_data = origem_df.iloc[train_size:]\n",
        "\n",
        "    # Extract the endogenous variable\n",
        "    endog_train = train_data['Vl Liquido Final']\n",
        "    endog_test = test_data['Vl Liquido Final']\n",
        "\n",
        "    # Fit SARIMA model using auto_arima\n",
        "    try:\n",
        "        stepwise_model = pm.auto_arima(endog_train, start_p=1, start_q=1,\n",
        "                                       max_p=3, max_q=3, m=12,\n",
        "                                       start_P=0, seasonal=True,\n",
        "                                       d=None, D=1, trace=False,\n",
        "                                       error_action='ignore',\n",
        "                                       suppress_warnings=True,\n",
        "                                       stepwise=True)\n",
        "\n",
        "        # Fit the model\n",
        "        model = SARIMAX(endog_train, order=stepwise_model.order, seasonal_order=stepwise_model.seasonal_order)\n",
        "        model_fit = model.fit(disp=False)\n",
        "\n",
        "        # Forecast for the test period\n",
        "        predictions_test = model_fit.forecast(steps=len(endog_test))\n",
        "\n",
        "        # Forecast for the next 12 months from the end of the test set\n",
        "        predictions_future = model_fit.forecast(steps=12)\n",
        "\n",
        "        # Evaluate the model on the test set\n",
        "        mae, rmse, mape = evaluate_model(endog_test, predictions_test)\n",
        "\n",
        "        print(f\"Origem {origem} - MAE: {mae:.2f}, RMSE: {rmse:.2f}, MAPE: {mape:.2f}%\")\n",
        "\n",
        "        # Plotting\n",
        "        plt.figure(figsize=(12,6))\n",
        "\n",
        "        # Plot actual data from test set\n",
        "        plt.plot(endog_test.index, endog_test, label='Valores Reais (2023)', color='blue', marker=\"o\")\n",
        "\n",
        "        # Plot predicted data for test set\n",
        "        plt.plot(endog_test.index, predictions_test, label='Valores Previstos (Teste)', linestyle='--', color='green', marker=\"o\")\n",
        "\n",
        "        # Plot forecast for next 12 months\n",
        "        future_dates = pd.date_range(endog_test.index[-1], periods=12, freq='M')\n",
        "        plt.plot(future_dates, predictions_future, label='Previsão Futura (12 meses)', linestyle='--', color='red', marker=\"o\")\n",
        "\n",
        "        # Vertical line to mark the end of training\n",
        "        plt.axvline(x=endog_test.index[-1], color='black', linestyle=':', label='Divisão Treino/Real')\n",
        "\n",
        "        plt.grid(True, linestyle=\"-\", which=\"major\", color=\"black\", linewidth=\"0.5\")\n",
        "        plt.title(f'Origem {origem} - Receita da Rede Gazeta (2023 até agora e previsão futura)')\n",
        "        plt.xlabel('Data')\n",
        "        plt.ylabel('Valor Líquido Final')\n",
        "\n",
        "        # Customize legend for clarity\n",
        "        plt.legend(loc='upper left')\n",
        "\n",
        "        # Display plot\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred for Origem {origem}: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
